{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape Amazon Page Notebook\n",
    "I will be web scraping the data that will go into a MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports the BeautifulSoup module from library bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "db = client['television_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a collection (table) to store the product information\n",
    "product_info_collection = db['product_information']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrape Part 1: Obtain Individual Item Links\n",
    "\n",
    "## Part A: Obtain The First Page of Results\n",
    "\n",
    "I will be web scraping Amazon's most featured televisions page. I will first store the urls of each individual television.\n",
    "\n",
    "The first results page has a different format than the following pages. I will not create a function for the first page because of this reason.\n",
    "\n",
    "After I obtain the first few links I will add them to a new MongoDB collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The link to the first page of results for televisions on Amazon, sorted by the default \"Featured\" option\n",
    "amazon_first_page_url_tvs = 'https://www.amazon.com/s/ref=lp_1266092011_nr_n_12?fst=as%3Aoff&rh=n%3A172282%2Cn%3A%21493964%2Cn%3A1266092011%2Cn%3A172659&bbn=1266092011&ie=UTF8&qid=1564525104&rnid=1266092011'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the first page of search results for televisions on Amazon\n",
    "amazon_first_page_url_tvs_html = requests.get(amazon_first_page_url_tvs, headers=headers, timeout=5).text #it will keep trying at this stage, the loop will not continue to iterate until a response is given\n",
    "amazon_first_page_url_tvs_content = BeautifulSoup(amazon_first_page_url_tvs_html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page_html_split_by_result = str(amazon_first_page_url_tvs_content).split('result_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page_tv_links = []\n",
    "\n",
    "for i in first_page_html_split_by_result[1:]:\n",
    "    \n",
    "    tv_link = BeautifulSoup(i, 'html.parser').find('a', class_=\"a-link-normal a-text-normal\")['href'].split('/ref')[0]\n",
    "    \n",
    "    first_page_tv_links.append({'url': tv_link})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(first_page_tv_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Add The First Page Of Results To Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertion_results = product_info_collection.insert_many(first_page_tv_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = product_info_collection.find({}, {'_id': 0, 'url': 1})\n",
    "for item in query_1:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Obtain The Subsequent Pages of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_page_tv_links(url):\n",
    "    \n",
    "    amazon_page_tv_html = requests.get(url, headers=headers, timeout=5).text\n",
    "    amazon_page_tv_html_content = BeautifulSoup(str(BeautifulSoup(amazon_page_tv_html, 'html.parser')), 'html.parser')\n",
    "\n",
    "    html_tv_urls = amazon_page_tv_html_content.find('div', class_ = 's-result-list s-search-results sg-row')\n",
    "    html_list_of_tv_urls = html_tv_urls.find_all('a', class_ = 'a-link-normal a-text-normal')\n",
    "    html_list_of_tv_urls = html_list_of_tv_urls[:24]\n",
    "    \n",
    "    list_of_dictionaries_of_television_urls = []\n",
    "    \n",
    "    for i in html_list_of_tv_urls:\n",
    "        list_of_dictionaries_of_television_urls.append({'url': 'https://www.amazon.com' + i['href'].split('/ref')[0]})\n",
    "    \n",
    "    return list_of_dictionaries_of_television_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "return_page_tv_links('https://www.amazon.com/s?rh=n%3A172282%2Cn%3A%21493964%2Cn%3A1266092011%2Cn%3A172659&page=13&qid=1564698515&ref=lp_172659_pg_2')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_urls(start_page = False, end_page = False):\n",
    "    amazon_tvs_url = 'https://www.amazon.com/s?rh=n%3A172282%2Cn%3A%21493964%2Cn%3A1266092011%2Cn%3A172659&page={}&qid=1564698515&ref=lp_172659_pg_2'\n",
    "    \n",
    "    if not start_page:\n",
    "        start_page = 2\n",
    "        \n",
    "    if not end_page:\n",
    "        end_page = 100\n",
    "    \n",
    "    for i in range(start_page, end_page):\n",
    "        one_page_of_amazon_tvs_url = amazon_tvs_url.format(str(i))\n",
    "        product_info_collection.insert_many(return_page_tv_links(one_page_of_amazon_tvs_url))\n",
    "        print('The total number of tv urls added are: {}'.format(product_info_collection.count_documents({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obtain_urls(start_page = 0, end_page = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info_collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info_collection.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
